{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Muon vs. AdamW Experiment Analysis\n",
        "\n",
        "This notebook analyzes the results of the OMat24 experiments, comparing the performance and learning geometry of the Muon optimizer against AdamW.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "# Load the metrics data\n",
        "try:\n",
        "    df_full = pd.read_csv('results/metrics.csv')\n",
        "    \n",
        "    # The first unnamed run is the baseline, let's give it a proper name\n",
        "    # Find the row where the run name changes to identify the end of the first run\n",
        "    first_run_end_idx = df_full[df_full['run'] != df_full['run'].iloc[0]].index[0]\n",
        "    df_full.loc[:first_run_end_idx-1, 'run'] = 'omat24_baseline'\n",
        "\n",
        "    print(\"Data loaded successfully.\")\n",
        "    display(df_full.head())\n",
        "    print(\"\\nFinal epoch metrics for each run:\")\n",
        "    display(df_full.groupby('run').last())\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: results/metrics.csv not found.\")\n",
        "    print(\"Please make sure you have downloaded the results from the GPU.\")\n",
        "except IndexError:\n",
        "    print(\"Warning: Could not automatically rename the baseline run. The CSV might only contain one experiment type.\")\n",
        "    display(df_full.head())\n",
        "\n",
        "\n",
        "# Set plot style\n",
        "sns.set_theme(style=\"whitegrid\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 8))\n",
        "ax = sns.lineplot(data=df_full, x='epoch', y='val_mae', hue='run', marker='o', alpha=0.8)\n",
        "\n",
        "ax.set_title('Validation MAE vs. Epoch for Different Optimizers', fontsize=16)\n",
        "ax.set_xlabel('Epoch', fontsize=12)\n",
        "ax.set_ylabel('Validation Mean Absolute Error (MAE)', fontsize=12)\n",
        "ax.legend(title='Optimizer Run')\n",
        "ax.set_yscale('log')\n",
        "ax.grid(True, which=\"both\", ls=\"--\")\n",
        "\n",
        "\n",
        "# Annotate the minimum MAE for each run\n",
        "for run_name in df_full['run'].unique():\n",
        "    run_df = df_full[df_full['run'] == run_name].dropna(subset=['val_mae'])\n",
        "    if not run_df.empty:\n",
        "        min_mae_row = run_df.loc[run_df['val_mae'].idxmin()]\n",
        "        \n",
        "        plt.annotate(f'{min_mae_row[\"val_mae\"]:.4f}',\n",
        "                     (min_mae_row['epoch'], min_mae_row['val_mae']),\n",
        "                     textcoords=\"offset points\",\n",
        "                     xytext=(0,10),\n",
        "                     ha='center',\n",
        "                     arrowprops=dict(arrowstyle=\"->\", connectionstyle=\"arc3,rad=.2\"))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Manually create a DataFrame with the final test set results from the eval script\n",
        "test_results = {\n",
        "    \"run\": [\n",
        "        \"omat24_baseline\",\n",
        "        \"omat24_muon_full\",\n",
        "        \"omat24_muon_no_ortho\",\n",
        "        \"omat24_muon_firstk\",\n",
        "    ],\n",
        "    \"Final Test MAE\": [0.3296, 0.4087, 0.3844, 0.3238],\n",
        "    \"Final Test RMSE\": [0.4183, 0.5095, 0.4737, 0.4107],\n",
        "}\n",
        "df_test = pd.DataFrame(test_results)\n",
        "\n",
        "print(\"--- Final Test Set Performance ---\")\n",
        "# Sort by the most important metric to see the winner clearly\n",
        "display(df_test.sort_values(\"Final Test MAE\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clean up run names for plotting\n",
        "df_test['run_label'] = df_test['run'].str.replace('omat24_', '').str.replace('_', ' ').str.title()\n",
        "\n",
        "# Create the bar plot\n",
        "plt.figure(figsize=(12, 7))\n",
        "ax = sns.barplot(data=df_test.sort_values(\"Final Test MAE\"), \n",
        "                 x='run_label', y='Final Test MAE', \n",
        "                 hue='run_label', palette='plasma', dodge=False)\n",
        "\n",
        "ax.set_title('Final Test Set MAE by Optimizer Strategy', fontsize=16)\n",
        "ax.set_xlabel('Optimizer Strategy', fontsize=12)\n",
        "ax.set_ylabel('Final Mean Absolute Error (MAE)', fontsize=12)\n",
        "plt.xticks(rotation=15, ha='right')\n",
        "ax.get_legend().remove() # Remove redundant legend\n",
        "\n",
        "# Add annotations to the bars\n",
        "for p in ax.patches:\n",
        "    ax.annotate(f'{p.get_height():.4f}', \n",
        "                (p.get_x() + p.get_width() / 2., p.get_height()), \n",
        "                ha = 'center', va = 'center', \n",
        "                xytext = (0, 9), \n",
        "                textcoords = 'offset points',\n",
        "                fontsize=12, weight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract the final epoch metrics for each run\n",
        "final_metrics = df_full.groupby('run').last().reset_index()\n",
        "\n",
        "# Select only the rattle MAE columns\n",
        "rattle_mae_cols = ['val_mae_low_rattle', 'val_mae_medium_rattle', 'val_mae_high_rattle']\n",
        "plot_data = final_metrics[['run'] + rattle_mae_cols]\n",
        "\n",
        "# Melt the dataframe to make it suitable for a bar plot\n",
        "plot_data_melted = plot_data.melt(id_vars='run', var_name='Rattle Level', value_name='Final MAE')\n",
        "\n",
        "# Clean up the names for the plot\n",
        "plot_data_melted['Rattle Level'] = plot_data_melted['Rattle Level'].str.replace('val_mae_', '').str.replace('_', ' ').str.title()\n",
        "\n",
        "# Create the bar plot\n",
        "plt.figure(figsize=(14, 8))\n",
        "ax = sns.barplot(data=plot_data_melted, x='run', y='Final MAE', hue='Rattle Level', palette='viridis')\n",
        "\n",
        "ax.set_title('Final Validation MAE by Optimizer and Structure Rattle Level', fontsize=16)\n",
        "ax.set_xlabel('Optimizer Run', fontsize=12)\n",
        "ax.set_ylabel('Final Validation MAE', fontsize=12)\n",
        "plt.xticks(rotation=15, ha='right')\n",
        "\n",
        "# Add annotations to the bars\n",
        "for p in ax.patches:\n",
        "    if p.get_height() > 0:\n",
        "        ax.annotate(f'{p.get_height():.4f}', \n",
        "                    (p.get_x() + p.get_width() / 2., p.get_height()), \n",
        "                    ha = 'center', va = 'center', \n",
        "                    xytext = (0, 9), \n",
        "                    textcoords = 'offset points')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
