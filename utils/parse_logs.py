"""
This script parses the raw .log files generated by the training runs and
compiles the key metrics into a clean, well-formatted CSV file suitable for analysis.
This is the robust, reproducible way to generate our final results dataset.
"""
import re
import csv
from pathlib import Path
import argparse


def parse_log_file(file_path: Path) -> list[dict]:
    """Extracts structured epoch data from a single log file."""
    run_name = file_path.stem.replace('_', ' ').replace(' full', '').replace(' no ortho', '-no-ortho').title().replace(' ', '-')
    
    # A more robust regex to capture all metrics, including the new rattle buckets
    epoch_pattern = re.compile(
        r"epoch (\d+) \| train_loss=([\d.]+) \| train_mae=([\d.]+).*?"
        r"val_mae=([\d.]+) \| val_rmse=([\d.]+).*?"
        r"val_mae_rattle \(low/med/high\)=([\d.]+)/([\d.]+)/([\d.]+)"
    )
    
    all_metrics = []
    with file_path.open('r') as f:
        content = f.read()
        
    matches = epoch_pattern.finditer(content)
    
    for match in matches:
        epoch_data = match.groups()
        all_metrics.append({
            "run": run_name,
            "epoch": int(epoch_data[0]),
            "train_loss": float(epoch_data[1]),
            "train_mae": float(epoch_data[2]),
            "val_mae": float(epoch_data[3]),
            "val_rmse": float(epoch_data[4]),
            "val_mae_low_rattle": float(epoch_data[5]),
            "val_mae_medium_rattle": float(epoch_data[6]),
            "val_mae_high_rattle": float(epoch_data[7]),
        })
        
    return all_metrics


def main():
    """Main function to find logs, parse them, and write a clean CSV."""
    parser = argparse.ArgumentParser(description="Parse training logs into a clean CSV.")
    parser.add_argument(
        "--log-dir",
        type=Path,
        default=Path("results"),
        help="Directory containing the .log files.",
    )
    parser.add_argument(
        "--output-file",
        type=Path,
        default=Path("results/metrics_clean.csv"),
        help="Path to the output CSV file.",
    )
    args = parser.parse_args()
    
    log_files = list(args.log_dir.glob("*.log"))
    if not log_files:
        print(f"Error: No .log files found in {args.log_dir}")
        return
        
    print(f"Found {len(log_files)} log files to parse...")
    
    all_data = []
    for log_file in log_files:
        print(f"  - Parsing {log_file.name}...")
        all_data.extend(parse_log_file(log_file))
        
    if not all_data:
        print("Error: No valid epoch data could be parsed from the log files.")
        return

    # Write to CSV
    header = all_data[0].keys()
    with args.output_file.open('w', newline='') as f:
        writer = csv.DictWriter(f, fieldnames=header)
        writer.writeheader()
        writer.writerows(all_data)
        
    print(f"\nSuccessfully created clean metrics file at: {args.output_file}")


if __name__ == "__main__":
    main()
